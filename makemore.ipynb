{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcleantom/makemore_from_scratch/blob/main/makemore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J21mMwQ7nf2w"
      },
      "source": [
        "Makes more things like it... character level language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2ECtyVhnzoF"
      },
      "outputs": [],
      "source": [
        "words = open('names.txt', 'r').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84UH0SK_ndx4",
        "outputId": "da56e098-b9b7-4683-8fff-cc36976b0d6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eSXTqGBIoO4v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "rCGufScwo9Hd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros((27, 27), dtype=torch.int32)"
      ],
      "metadata": {
        "id": "9Dte2w5qpubX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s: i+1 for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i: s for s, i in stoi.items()}"
      ],
      "metadata": {
        "id": "cbKH6L2Kp_FF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    N[ix1, ix2] += 1"
      ],
      "metadata": {
        "id": "kFzzl-v3qYdt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P = (N+1).float()  # + 1 means that combinations that dont exist in the dataset (i.e aj) get atleast 1 count (model smoothing)\n",
        "P = P / P.sum(1, keepdim=True)"
      ],
      "metadata": {
        "id": "8Wq7hk8OsEIc"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for _ in range(20):\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    p = P[ix]\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtyzzIwvsYbJ",
        "outputId": "b0aef61b-3a0e-43f4-9d52-d8a78e8235f7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mor.\n",
            "axx.\n",
            "minaymoryles.\n",
            "kondlaisah.\n",
            "anchshizarie.\n",
            "odaren.\n",
            "iaddash.\n",
            "h.\n",
            "jhinatien.\n",
            "egushl.\n",
            "h.\n",
            "br.\n",
            "a.\n",
            "jayn.\n",
            "ilemannariaenien.\n",
            "be.\n",
            "f.\n",
            "akiinela.\n",
            "trttanakeroruceyaaxatona.\n",
            "lamoynayrkiedengin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal is to maximize the likeleyhood of the data w.r.t. model parameters (statistical modeling)\n",
        "\n",
        "1. Equivalent to maximizing the log likelyhood\n",
        "\n",
        "2. Equivalent to minimizing the negative log likelyhood\n",
        "\n",
        "3. Equivalent to minimizing the average negative log likelyhood"
      ],
      "metadata": {
        "id": "n62Ot_ivw_Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training set of all the bigrams\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "2Rk3fSPhwFRo"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "xenc = F.one_hot(xs, num_classes=27).float()\n",
        "plt.imshow(xenc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "kYxZ5kA_0CLg",
        "outputId": "739935c5-7260-4bd4-e84f-afa79223f600"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9e560fefd0>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn((27, 27))\n",
        "logits = (xenc @ W)  # log-counts\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdims=True) \n",
        "probs  ## Last two lines is called softmax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9D66Wgp0WNu",
        "outputId": "ba0640d2-bccd-4d11-c7b3-f10fcb05c4ee"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0256, 0.0355, 0.0219, 0.0086, 0.0062, 0.0456, 0.0604, 0.0934, 0.0544,\n",
              "         0.0303, 0.1084, 0.0227, 0.0180, 0.0511, 0.0445, 0.0171, 0.0289, 0.0946,\n",
              "         0.0329, 0.0142, 0.0437, 0.0073, 0.0725, 0.0082, 0.0120, 0.0255, 0.0166],\n",
              "        [0.0644, 0.0377, 0.0068, 0.0961, 0.0516, 0.0441, 0.0210, 0.0643, 0.0147,\n",
              "         0.0320, 0.0210, 0.0161, 0.0362, 0.0161, 0.0728, 0.0731, 0.0457, 0.0224,\n",
              "         0.0478, 0.0150, 0.0919, 0.0065, 0.0519, 0.0193, 0.0073, 0.0180, 0.0060],\n",
              "        [0.0155, 0.0384, 0.0181, 0.0414, 0.0603, 0.0332, 0.1021, 0.0949, 0.1659,\n",
              "         0.0200, 0.0084, 0.0562, 0.0130, 0.0060, 0.0229, 0.0193, 0.0092, 0.0137,\n",
              "         0.1158, 0.0290, 0.0062, 0.0153, 0.0040, 0.0232, 0.0073, 0.0096, 0.0511],\n",
              "        [0.0155, 0.0384, 0.0181, 0.0414, 0.0603, 0.0332, 0.1021, 0.0949, 0.1659,\n",
              "         0.0200, 0.0084, 0.0562, 0.0130, 0.0060, 0.0229, 0.0193, 0.0092, 0.0137,\n",
              "         0.1158, 0.0290, 0.0062, 0.0153, 0.0040, 0.0232, 0.0073, 0.0096, 0.0511],\n",
              "        [0.0465, 0.0064, 0.0351, 0.0527, 0.0983, 0.0709, 0.0110, 0.0137, 0.0287,\n",
              "         0.0096, 0.0132, 0.0489, 0.0245, 0.1191, 0.0286, 0.0197, 0.0644, 0.0344,\n",
              "         0.0192, 0.0038, 0.0229, 0.0570, 0.0411, 0.0605, 0.0317, 0.0359, 0.0022]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = [], []\n",
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "I-WoYLhz34Fu"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NN\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
        "num = xs.nelement()\n",
        "\n",
        "for k in range(100):\n",
        "  xenc = F.one_hot(xs, num_classes=27).float()\n",
        "  logits = xenc @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  print(loss.item())\n",
        "  # backward pass\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  W.data += -50 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL-WigI81-29",
        "outputId": "d72032d1-38a3-4ed3-ee43-f7172b570d5d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7686190605163574\n",
            "3.3788065910339355\n",
            "3.16109037399292\n",
            "3.0271859169006348\n",
            "2.9344842433929443\n",
            "2.867231607437134\n",
            "2.8166542053222656\n",
            "2.777146339416504\n",
            "2.7452542781829834\n",
            "2.7188303470611572\n",
            "2.696505546569824\n",
            "2.6773719787597656\n",
            "2.6608052253723145\n",
            "2.6463515758514404\n",
            "2.633664846420288\n",
            "2.622471570968628\n",
            "2.6125476360321045\n",
            "2.6037068367004395\n",
            "2.595794916152954\n",
            "2.5886809825897217\n",
            "2.5822560787200928\n",
            "2.5764293670654297\n",
            "2.5711236000061035\n",
            "2.5662729740142822\n",
            "2.5618228912353516\n",
            "2.5577263832092285\n",
            "2.5539441108703613\n",
            "2.550442695617676\n",
            "2.5471925735473633\n",
            "2.5441696643829346\n",
            "2.5413522720336914\n",
            "2.538722038269043\n",
            "2.536262035369873\n",
            "2.5339581966400146\n",
            "2.531797409057617\n",
            "2.529768228530884\n",
            "2.527859926223755\n",
            "2.5260636806488037\n",
            "2.5243701934814453\n",
            "2.522773265838623\n",
            "2.52126407623291\n",
            "2.519836902618408\n",
            "2.5184857845306396\n",
            "2.5172054767608643\n",
            "2.515990734100342\n",
            "2.5148372650146484\n",
            "2.5137407779693604\n",
            "2.512697696685791\n",
            "2.511704921722412\n",
            "2.5107581615448\n",
            "2.509854555130005\n",
            "2.5089924335479736\n",
            "2.5081682205200195\n",
            "2.507380485534668\n",
            "2.5066261291503906\n",
            "2.5059032440185547\n",
            "2.5052106380462646\n",
            "2.5045459270477295\n",
            "2.5039076805114746\n",
            "2.503295421600342\n",
            "2.5027060508728027\n",
            "2.5021393299102783\n",
            "2.5015945434570312\n",
            "2.5010693073272705\n",
            "2.500562906265259\n",
            "2.500075578689575\n",
            "2.4996044635772705\n",
            "2.499150514602661\n",
            "2.4987120628356934\n",
            "2.498288154602051\n",
            "2.4978790283203125\n",
            "2.4974827766418457\n",
            "2.4970996379852295\n",
            "2.4967293739318848\n",
            "2.496370315551758\n",
            "2.4960227012634277\n",
            "2.4956858158111572\n",
            "2.4953596591949463\n",
            "2.4950435161590576\n",
            "2.494736433029175\n",
            "2.4944381713867188\n",
            "2.494149684906006\n",
            "2.4938690662384033\n",
            "2.4935967922210693\n",
            "2.4933323860168457\n",
            "2.493075132369995\n",
            "2.4928252696990967\n",
            "2.492582321166992\n",
            "2.49234676361084\n",
            "2.492116689682007\n",
            "2.4918932914733887\n",
            "2.491676092147827\n",
            "2.491464376449585\n",
            "2.491258382797241\n",
            "2.491058111190796\n",
            "2.4908623695373535\n",
            "2.4906723499298096\n",
            "2.4904870986938477\n",
            "2.4903063774108887\n",
            "2.4901304244995117\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfMAYlA2tAzWfwLg7wyNmJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}